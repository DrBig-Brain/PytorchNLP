{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2bd4acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"processed.csv\")\n",
    "df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5aafcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88edb860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject naturally irresistible your corporate ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject the stock trading gunslinger fanny is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject unbelievable new homes made easy im wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject 4 color printing special request addit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject do not have money get software cds fro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>subject re research and development charges to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>subject re receipts from visit jim thanks agai...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>subject re enron case study update wow all on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>subject re interest david please call shirley ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>subject news aurora 5 2 update aurora version ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Spam\n",
       "0     subject naturally irresistible your corporate ...     1\n",
       "1     subject the stock trading gunslinger fanny is ...     1\n",
       "2     subject unbelievable new homes made easy im wa...     1\n",
       "3     subject 4 color printing special request addit...     1\n",
       "4     subject do not have money get software cds fro...     1\n",
       "...                                                 ...   ...\n",
       "5723  subject re research and development charges to...     0\n",
       "5724  subject re receipts from visit jim thanks agai...     0\n",
       "5725  subject re enron case study update wow all on ...     0\n",
       "5726  subject re interest david please call shirley ...     0\n",
       "5727  subject news aurora 5 2 update aurora version ...     0\n",
       "\n",
       "[5728 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "693fd4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(texts,max_vocab_size=10000):\n",
    "    words = \" \".join(texts).split()\n",
    "    freq = Counter(words)\n",
    "    vocab = {'<PAD>':0,\"<UNK>\":1}\n",
    "    for idx, (word,_) in enumerate(freq.most_common(max_vocab_size - 2),start = 2)  :\n",
    "        vocab[word] = idx\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d1eec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab(df['Text'].tolist()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a6566cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(text, vocab, max_len=50):\n",
    "    tokens = text.split()\n",
    "    ids = [vocab.get(tok, vocab[\"<UNK>\"]) for tok in tokens]\n",
    "    if len(ids) < max_len:\n",
    "        ids += [vocab[\"<PAD>\"]] * (max_len - len(ids))\n",
    "    else:\n",
    "        ids = ids[:max_len]\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b3367a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "df['encoded'] = df['Text'].apply(lambda x: encode_text(x, vocab, max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6db4abdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['encoded'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ebcdc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dff5ab4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(df['encoded'].tolist(), dtype=torch.long)\n",
    "y = torch.tensor(df['Spam'].tolist(), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1551b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5add1bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c01c3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = SpamDataset(X_train, y_train)\n",
    "test_ds = SpamDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be24af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6571e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        out = self.fc(h_n[-1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3dfd845",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embed_dim = 128\n",
    "hidden_dim = 128\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c6420f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(vocab_size, embed_dim, hidden_dim, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2543a3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.4191\n",
      "Epoch 2/20, Loss: 0.1828\n",
      "Epoch 3/20, Loss: 0.1064\n",
      "Epoch 4/20, Loss: 0.0500\n",
      "Epoch 5/20, Loss: 0.0327\n",
      "Epoch 6/20, Loss: 0.0247\n",
      "Epoch 7/20, Loss: 0.0317\n",
      "Epoch 8/20, Loss: 0.0127\n",
      "Epoch 9/20, Loss: 0.0174\n",
      "Epoch 10/20, Loss: 0.0218\n",
      "Epoch 11/20, Loss: 0.0790\n",
      "Epoch 12/20, Loss: 0.0243\n",
      "Epoch 13/20, Loss: 0.0090\n",
      "Epoch 14/20, Loss: 0.0176\n",
      "Epoch 15/20, Loss: 0.0116\n",
      "Epoch 16/20, Loss: 0.0042\n",
      "Epoch 17/20, Loss: 0.0046\n",
      "Epoch 18/20, Loss: 0.0014\n",
      "Epoch 19/20, Loss: 0.0012\n",
      "Epoch 20/20, Loss: 0.0011\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4798f5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9782\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {correct/total:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
